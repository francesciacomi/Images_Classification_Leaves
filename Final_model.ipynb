{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["YFcIL1jc-l2M","kfe1y4UedMd5","pLb-N5JzUUQS","BDM82PpE3VSg","pKlzZszgzl9g","vPTDeDB_J5Yf","q3Hlpi5E-u5i","PFUOMUxVARTh","c5M9P5YiEZuG","wwdlXrmzp18k","th8yflyCGLO7","LWWrRa82E4nY","OBwf91PEfcJ_","jAFnUVPFq-Ma","zYM8fJf9q-Mc","sYNYPJzeq-Me","UluWVmeGq-Mg","scrVeYRQq-Mj","aRaKyBEMq-Ml","c99fbP_ctBdp"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SLdF79LdcP4U"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/polimi/ANN&DL"]},{"cell_type":"markdown","source":["# Pre-operations"],"metadata":{"id":"YFcIL1jc-l2M"}},{"cell_type":"markdown","metadata":{"id":"kfe1y4UedMd5"},"source":["###Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxZKtDIMc18q"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import random\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix\n","from PIL import Image\n","from keras.applications.xception import preprocess_input\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"pLb-N5JzUUQS"},"source":["### Set seed for reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C7HYua8HUHIj"},"outputs":[],"source":["# Random seed for reproducibility\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"BDM82PpE3VSg"},"source":["### Suppress warnings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fXtacjAqOIq"},"outputs":[],"source":["import warnings\n","import logging\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","tf.get_logger().setLevel('INFO')\n","tf.autograph.set_verbosity(0)\n","\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.get_logger().setLevel('ERROR')\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"]},{"cell_type":"markdown","metadata":{"id":"pKlzZszgzl9g"},"source":["##Load data\n","Load the dataset to be used for classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"slLAhUr5ZleP"},"outputs":[],"source":["dataset_dir_split = \"dataset_challenge1\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ys5aKmXIdP5m"},"outputs":[],"source":["labels = []\n","for i in range(1,9):\n","  labels.append(\"Species\"+str(i))\n","\n","print(labels) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGuNfmaCqkyP"},"outputs":[],"source":["training_dir = os.path.join(dataset_dir_split, 'train') \n","validation_dir = os.path.join(dataset_dir_split, 'val') \n","test_dir = os.path.join(dataset_dir_split, 'test') "]},{"cell_type":"code","source":["from keras.applications.efficientnet_v2 import preprocess_input"],"metadata":{"id":"3JxU9cbcP58F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","aug_generator= ImageDataGenerator(featurewise_center= False,\n","                                  samplewise_center= False,\n","                                  featurewise_std_normalization= True,\n","                                  samplewise_std_normalization= True,\n","                                  zca_whitening= False,\n","                                  rotation_range= 360,\n","                                  width_shift_range= 0.2,\n","                                  height_shift_range= 0.0,\n","                                  brightness_range=[0.2,0.7389633367497224],\n","                                  zoom_range= 0.2887325046461444,\n","                                  fill_mode= \"nearest\",\n","                                  horizontal_flip= False,\n","                                  vertical_flip= False)"],"metadata":{"id":"pJuEB-FNheM1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5e4rIuEaepmR"},"outputs":[],"source":["aug_train_gen = aug_generator.flow_from_directory(directory=training_dir,\n","                                                       target_size=(96,96),\n","                                                       color_mode='rgb',\n","                                                       classes=None,\n","                                                       class_mode='categorical',\n","                                                       batch_size=8,\n","                                                       shuffle=True,\n","                                                       seed=seed)\n","                                             \n","                                             \n","valid_gen = ImageDataGenerator(\n","    ).flow_from_directory(directory=validation_dir,\n","                                               target_size=(96,96),\n","                                               color_mode='rgb',\n","                                               classes=None, # can be set to labels\n","                                               class_mode='categorical',\n","                                               batch_size=8,\n","                                               shuffle=False,\n","                                               seed=seed)\n","test_gen = ImageDataGenerator(\n",").flow_from_directory(directory=test_dir,\n","                                              target_size=(96,96),\n","                                              color_mode='rgb',\n","                                              classes=None, # can be set to labels\n","                                              class_mode='categorical',\n","                                              batch_size=8,\n","                                              shuffle=False,\n","                                              seed=seed)"]},{"cell_type":"markdown","metadata":{"id":"vPTDeDB_J5Yf"},"source":["###Weights"]},{"cell_type":"code","source":["from sklearn.utils import compute_class_weight\n","\n","train_classes= aug_train_gen.classes\n","class_weights = compute_class_weight(\n","                                        class_weight = \"balanced\",\n","                                        classes = np.unique(train_classes),\n","                                        y = train_classes                                                    \n","                                    )\n","class_weights = dict(zip(np.unique(train_classes), class_weights))\n","class_weights"],"metadata":{"id":"DCH6_LCJi7C2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model\n","The model is an ensemble of two EfficientNet models, one EfficientNetS and one EfficientNetL, which works on the unbalanced dataset. Indeed, the dataset used for the training process is just the dataset of the competition splitted in train, validation and test. The fact that the dataset is unbalanced produces worst results especially in the less represented classes (e.g. Species 1). To solve this problem we used the compute_class_weight method offered by sklearn in order to weight the loss function. "],"metadata":{"id":"q3Hlpi5E-u5i"}},{"cell_type":"markdown","source":["##*EfficientS*\n","\n","The first model takes the CNN part from the EfficientNetV2S while the FC layer is characterized by a Dropout layer, a Dense layer, Leaky Relu, a Dropout layer and the output layer.\n","1. The following was the initial structure of the model where the hyperparameters, like, for instance, the number of units for the dense layer where chosen by us. "],"metadata":{"id":"PFUOMUxVARTh"}},{"cell_type":"code","source":["def build_model(hp):\n","\n","  supernet = tfk.applications.EfficientNetV2S(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_shape=(96,96,3),\n","    pooling='avg',\n","    include_preprocessing=True\n",")\n","  \n","  elastic_lambda=1e-3\n","\n","  # Use the supernet as feature extractor\n","  supernet.trainable = False\n","\n","  inputs = tfk.Input(shape=(96,96,3))\n","  x = tfkl.Resizing(96,96, interpolation=\"bicubic\")(inputs)\n","  x = supernet(x)\n","  x = tfkl.Dropout(0.5, seed=seed)(x)    #0.3\n","  x = tfkl.Dense( \n","      units=512, \n","      kernel_initializer = tfk.initializers.HeUniform(seed),\n","      kernel_regularizer=tf.keras.regularizers.L1L2(elastic_lambda,elastic_lambda))(x)\n","  x=tfkl.LeakyReLU()(x)\n","  x = tfkl.Dropout(0.5, seed=seed)(x)    #0.3\n","  outputs = tfkl.Dense(\n","      8, \n","      activation='softmax',\n","      kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n","\n","\n","  # Connect input and output through the Model class\n","  tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","  learning_rate = 1e-4\n","  tl_model.compile(\n","  optimizer=tfk.optimizers.Adam(learning_rate=learning_rate),\n","  loss=\"categorical_crossentropy\",\n","  metrics=[\"accuracy\"],\n","  )\n","  return tl_model"],"metadata":{"id":"L7G8z50XDBBu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. To improve the results we decided to use hyperparameter tuning in order to find the best combination of hyperparameters for the model. This uses the keras-tuner module. We used the hyperparameter tuning also to find the best combination of augmentation."],"metadata":{"id":"yob60n2uDuhs"}},{"cell_type":"markdown","source":["#### install & import keras tuner"],"metadata":{"id":"c5M9P5YiEZuG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFqGcw709fsr"},"outputs":[],"source":["!pip install keras-tuner -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jbHEamBk9h-N"},"outputs":[],"source":["import keras_tuner"]},{"cell_type":"markdown","source":["####Model definition"],"metadata":{"id":"wwdlXrmzp18k"}},{"cell_type":"code","source":["def build_model(hp):\n","  \n","################AUGMENTATION############################\n","\n","  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","  aug_train_gen = ImageDataGenerator(featurewise_center=hp.Boolean(\"featurewise_center\"),\n","                                    samplewise_center=hp.Boolean(\"samplewise_center\"),\n","                                    featurewise_std_normalization=hp.Boolean(\"featurewise_std_normalization\"),\n","                                    samplewise_std_normalization=hp.Boolean(\"samplewise_std_normalization\"),\n","                                    zca_whitening=hp.Boolean(\"zca_whitening\"),\n","                                    rotation_range=hp.Int(\"rotation_range\",min_value=0,max_value=360,step=10),\n","                                    width_shift_range=hp.Choice(\"width_shift_range\",[0.0,0.2]),\n","                                    height_shift_range=hp.Choice(\"height_shift_range\",[0.0,0.2]),\n","                                    brightness_range=[0.2,hp.Float(\"max_rotation\",min_value=0.3,max_value=1.4)],\n","                                    zoom_range=hp.Float(\"zoom_range\",min_value=0,max_value=1),\n","                                    fill_mode=hp.Choice(\"fill_mode\",['nearest','constant','wrap','reflect']),\n","                                    horizontal_flip=hp.Boolean(\"horizontal_flip\"),\n","                                    vertical_flip=hp.Boolean(\"vertical_flip\"),\n","                                              ).flow_from_directory(directory=training_dir,\n","                                                        target_size=(96,96),\n","                                                        color_mode='rgb',\n","                                                        classes=None,\n","                                                        class_mode='categorical',\n","                                                        batch_size=8,\n","                                                        shuffle=True,\n","                                                        seed=seed)\n","                                              \n","                                              \n","  valid_gen = ImageDataGenerator(\n","      ).flow_from_directory(directory=validation_dir,\n","                                                target_size=(96,96),\n","                                                color_mode='rgb',\n","                                                classes=None, # can be set to labels\n","                                                class_mode='categorical',\n","                                                batch_size=8,\n","                                                shuffle=False,\n","                                                seed=seed)\n","  test_gen = ImageDataGenerator(\n","  ).flow_from_directory(directory=test_dir,\n","                                                target_size=(96,96),\n","                                                color_mode='rgb',\n","                                                classes=None, # can be set to labels\n","                                                class_mode='categorical',\n","                                                batch_size=8,\n","                                                shuffle=False,\n","                                                seed=seed)\n","##########################################################\n","  supernet = tfk.applications.EfficientNetV2S(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_shape=(96,96,3),\n","    pooling='avg',\n","    include_preprocessing=True\n",")\n","  \n","  elastic_lambda= hp.Float(\"reg\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n","\n","  # Use the supernet as feature extractor\n","  supernet.trainable = False\n","\n","  inputs = tfk.Input(shape=(96,96,3))\n","  x = tfkl.Resizing(96,96, interpolation=\"bicubic\")(inputs)\n","  x = supernet(x)\n","  x = tfkl.Dropout(0.5, seed=seed)(x)    #0.3\n","  x = tfkl.Dense( \n","      units=hp.Int(\"units\", min_value=32, max_value=512, step=32), \n","      kernel_initializer = tfk.initializers.HeUniform(seed),\n","      kernel_regularizer=tf.keras.regularizers.L1L2(elastic_lambda,elastic_lambda))(x)\n","  x=tfkl.LeakyReLU()(x)\n","  x = tfkl.Dropout(0.5, seed=seed)(x)    #0.3\n","  outputs = tfkl.Dense(\n","      8, \n","      activation='softmax',\n","      kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n","\n","\n","  # Connect input and output through the Model class\n","  tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","  learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n","  tl_model.compile(\n","  optimizer=tfk.optimizers.Adam(learning_rate=learning_rate),\n","  loss=\"categorical_crossentropy\",\n","  metrics=[\"accuracy\"],\n","  )\n","  return tl_model"],"metadata":{"id":"GfwC320kAoBf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Hyperparameter search\n","1. build the model"],"metadata":{"id":"th8yflyCGLO7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCmENE7NhcTM"},"outputs":[],"source":["build_model(keras_tuner.HyperParameters())"]},{"cell_type":"markdown","source":["2. initialize the tuner. We decided to use a random search."],"metadata":{"id":"XiQP2kcfGmXQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yslyPwyLX2Pj"},"outputs":[],"source":["tuner = keras_tuner.RandomSearch(\n","    hypermodel=build_model,\n","    objective=\"val_accuracy\",\n","    max_trials=10,\n","    executions_per_trial=2,\n","    overwrite=False,\n","    directory=\"my_dir\",\n","    project_name=\"helloworld\",\n",")"]},{"cell_type":"markdown","source":["3. Run the search and get the results"],"metadata":{"id":"C5pDzmf0Gs7O"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPsqwv3swy4H"},"outputs":[],"source":["tuner.search(aug_train_gen,epochs=2, validation_data=valid_gen)\n","tuner.results_summary()"]},{"cell_type":"markdown","source":["4. Get the best model found by the hyperparameter tuning"],"metadata":{"id":"XRwg9EikGxyD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcoKrl9wXkbm"},"outputs":[],"source":["# Get the top 2 models.\n","models = tuner.get_best_models(num_models=2)\n","best_model = models[0]\n","# Build the model.\n","# Needed for `Sequential` without specified `input_shape`.\n","best_model.build(input_shape=(96,96,3))\n","best_model.summary()\n"]},{"cell_type":"markdown","source":["####Transfer learning\n","We run a transfer learning step directly on the best model found by the hyperparameter tuning"],"metadata":{"id":"LWWrRa82E4nY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-7i-2abn4Vd"},"outputs":[],"source":["# Train the model\n","best_history = best_model.fit(\n","    aug_train_gen,\n","    epochs = 200,  \n","    validation_data = valid_gen,\n","    class_weight=class_weights,\n","    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",").history"]},{"cell_type":"code","metadata":{"id":"3fziDMO1NTG2"},"source":["# Plot the training\n","plt.figure(figsize=(15,5))\n","plt.plot(best_history['loss'], label='Training', alpha=.3, color='blue')\n","plt.plot(best_history['val_loss'], label='Validation', alpha=.8, color='red')\n","plt.legend(loc='upper left')\n","plt.title('Categorical Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(best_history['accuracy'], label='Training', alpha=.8, color='blue')\n","plt.plot(best_history['val_accuracy'], label='Validation', alpha=.8, color='red')\n","plt.legend(loc='upper left')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bIZ9iwNEfF2b"},"outputs":[],"source":["# Predict the test set with the CNN\n","predictions = best_model.predict(test_gen)\n","predictions.shape\n","\n","pred=np.argmax(predictions,axis=1)\n","# Compute the confusion matrix\n","cm = confusion_matrix(test_gen.classes, pred)\n","\n","pred=np.argmax(predictions,axis=-1)\n","\n","# Compute the classification metrics\n","accuracy = accuracy_score(test_gen.classes, pred)\n","precision = precision_score(test_gen.classes, pred, average='macro')\n","recall = recall_score(test_gen.classes, pred, average='macro')\n","f1 = f1_score(test_gen.classes, pred, average='macro')\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(10,8))\n","sns.heatmap(cm.T, xticklabels=labels, yticklabels=labels)\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6XsI3gZdymh"},"outputs":[],"source":["best_model.save(\"ANN&DL_Model/TL_EFFNETS\")"]},{"cell_type":"markdown","metadata":{"id":"OBwf91PEfcJ_"},"source":["#### Fine tuning\n","Reload the model and run a step of fine tuning over it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PfPJePumjRjp"},"outputs":[],"source":["# Re-load the model after transfer learning\n","path='ANN&DL_Model'\n","ft_model = tfk.models.load_model(os.path.join(path, 'TL_EFFNETS'))\n","ft_model.summary()"]},{"cell_type":"markdown","source":[" Set all effnet layers to True. We kept the batch normalization layers freezed. We followed the keras documentation for Fine Tuning on the Efficient net. \"The BatchNormalization layers need to be kept frozen. If they are also turned to trainable, the first epoch after unfreezing will significantly reduce accuracy.\""],"metadata":{"id":"Q-ZJ3duWclGY"}},{"cell_type":"code","source":["\n","for i, layer in enumerate(ft_model.layers):  \n","   if not isinstance(layer, tfkl.BatchNormalization):\n","        layer.trainable=True\n","        \n","for i, layer in enumerate(ft_model.layers):  \n","    print(i, layer.name, layer.trainable)\n","ft_model.summary()"],"metadata":{"id":"VdnBjMG_cvXH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Freeze first 250 layers. The number of layers to freeze as been found experimentally. We tried with 150, 350 layers. The chosen combination was the one giving the best performance."],"metadata":{"id":"LYXtGlOPOKC1"}},{"cell_type":"code","source":["\n","for i, layer in enumerate(ft_model.get_layer('efficientnetv2-s').layers[:250]):  \n","        layer.trainable=False\n","        \n","for i, layer in enumerate(ft_model.get_layer('efficientnetv2-s').layers):  \n","     if isinstance(layer, tfkl.BatchNormalization):\n","        layer.trainable=False\n","        \n","for i, layer in enumerate(ft_model.get_layer('efficientnetv2-s').layers):  \n","   print(i, layer.name, layer.trainable)\n","ft_model.summary()"],"metadata":{"id":"abtGReSccz6d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For the finetuning we used a learning rate 10 times smaller than the one used for the transfer learning phase."],"metadata":{"id":"uNlcVqDoORIA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kb3wq2DNFgCZ"},"outputs":[],"source":["# Compile the model\n","ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gReRof3iferf"},"outputs":[],"source":["# Fine-tune the model\n","ft_history = ft_model.fit(\n","    x = aug_train_gen,\n","    batch_size = 256,\n","    epochs = 200,\n","    validation_data = valid_gen,\n","    class_weight=w,\n","    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",").history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BnG-gxQTIdkr"},"outputs":[],"source":["# Plot the training\n","plt.figure(figsize=(15,5))\n","plt.plot(tl_history['loss'], alpha=.3, color='#4D61E2', linestyle='--')\n","plt.plot(tl_history['val_loss'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n","plt.plot(ft_history['loss'], alpha=.3, color='#2ABC3D', linestyle='--')\n","plt.plot(ft_history['val_loss'], label='Fine Tuning', alpha=.8, color='#2ABC3D')\n","plt.legend(loc='upper left')\n","plt.title('Categorical Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(tl_history['accuracy'], alpha=.3, color='#4D61E2', linestyle='--')\n","plt.plot(tl_history['val_accuracy'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n","plt.plot(ft_history['accuracy'], alpha=.3, color='#2ABC3D', linestyle='--')\n","plt.plot(ft_history['val_accuracy'], label='Fine Tuning', alpha=.8, color='#2ABC3D')\n","plt.legend(loc='upper left')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFfM7vSfJMPo"},"outputs":[],"source":["# Predict the test set with the CNN\n","predictions = ft_model.predict(test_gen)\n","predictions.shape\n","\n","pred=np.argmax(predictions,axis=1)\n","# Compute the confusion matrix\n","cm = confusion_matrix(test_gen.classes, pred)\n","\n","pred=np.argmax(predictions,axis=-1)\n","\n","# Compute the classification metrics\n","accuracy = accuracy_score(test_gen.classes, pred)\n","precision = precision_score(test_gen.classes, pred, average='macro')\n","recall = recall_score(test_gen.classes, pred, average='macro')\n","f1 = f1_score(test_gen.classes, pred, average='macro')\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(10,8))\n","sns.heatmap(cm.T, xticklabels=labels, yticklabels=labels)\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YEJT9OVttR0C"},"outputs":[],"source":["ft_model.save('ANN&DL_Model/FT_EFFNETS_85')"]},{"cell_type":"code","source":[],"metadata":{"id":"kyatGh8oq6px"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##*EfficientL*\n","\n","The second model takes the CNN part from the EfficientNetV2L while the FC layer is characterized by a Dropout layer, a Dense layer, Leaky Relu, a Dropout layer and the output layer.\n","1. The following was the initial structure of the model where the hyperparameters, like, for instance, the number of units for the dense layer where chosen by us. "],"metadata":{"id":"jAFnUVPFq-Ma"}},{"cell_type":"code","source":["def build_model(hp):\n","\n","  supernet = tfk.applications.EfficientNetV2L(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_shape=(96,96,3),\n","    pooling='avg',\n","    include_preprocessing=True\n",")\n","  \n","  elastic_lambda=1e-3\n","\n","  # Use the supernet as feature extractor\n","  supernet.trainable = False\n","\n","  inputs = tfk.Input(shape=(96,96,3))\n","  x = tfkl.Resizing(96,96, interpolation=\"bicubic\")(inputs)\n","  x = supernet(x)\n","  x = tfkl.Dropout(0.5, seed=seed)(x)    #0.3\n","  x = tfkl.Dense( \n","      units=512, \n","      kernel_initializer = tfk.initializers.HeUniform(seed),\n","      kernel_regularizer=tf.keras.regularizers.L1L2(elastic_lambda,elastic_lambda))(x)\n","  x=tfkl.LeakyReLU()(x)\n","  x = tfkl.Dropout(0.5, seed=seed)(x)    #0.3\n","  outputs = tfkl.Dense(\n","      8, \n","      activation='softmax',\n","      kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n","\n","\n","  # Connect input and output through the Model class\n","  tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","  learning_rate = 1e-4\n","  tl_model.compile(\n","  optimizer=tfk.optimizers.Adam(learning_rate=learning_rate),\n","  loss=\"categorical_crossentropy\",\n","  metrics=[\"accuracy\"],\n","  )\n","  return tl_model"],"metadata":{"id":"V83kW3GQq-Mb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. To improve the results we decided to use hyperparameter tuning in order to find the best combination of hyperparameters for the model. This uses the keras-tuner module. We used the hyperparameter tuning also to find the best combination of augmentation."],"metadata":{"id":"kOyxwlOLq-Mc"}},{"cell_type":"markdown","source":["#### install & import keras tuner"],"metadata":{"id":"zYM8fJf9q-Mc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-sL9SDyXq-Md"},"outputs":[],"source":["!pip install keras-tuner -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JqDEhNhEq-Me"},"outputs":[],"source":["import keras_tuner"]},{"cell_type":"markdown","source":["####Model definition"],"metadata":{"id":"sYNYPJzeq-Me"}},{"cell_type":"code","source":["def build_model(hp):\n","  \n","################AUGMENTATION############################\n","\n","  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","  aug_train_gen = ImageDataGenerator(featurewise_center=hp.Boolean(\"featurewise_center\"),\n","                                    samplewise_center=hp.Boolean(\"samplewise_center\"),\n","                                    featurewise_std_normalization=hp.Boolean(\"featurewise_std_normalization\"),\n","                                    samplewise_std_normalization=hp.Boolean(\"samplewise_std_normalization\"),\n","                                    zca_whitening=hp.Boolean(\"zca_whitening\"),\n","                                    rotation_range=hp.Int(\"rotation_range\",min_value=0,max_value=360,step=10),\n","                                    width_shift_range=hp.Choice(\"width_shift_range\",[0.0,0.2]),\n","                                    height_shift_range=hp.Choice(\"height_shift_range\",[0.0,0.2]),\n","                                    brightness_range=[0.2,hp.Float(\"max_rotation\",min_value=0.3,max_value=1.4)],\n","                                    zoom_range=hp.Float(\"zoom_range\",min_value=0,max_value=1),\n","                                    fill_mode=hp.Choice(\"fill_mode\",['nearest','constant','wrap','reflect']),\n","                                    horizontal_flip=hp.Boolean(\"horizontal_flip\"),\n","                                    vertical_flip=hp.Boolean(\"vertical_flip\"),\n","                                              ).flow_from_directory(directory=training_dir,\n","                                                        target_size=(96,96),\n","                                                        color_mode='rgb',\n","                                                        classes=None,\n","                                                        class_mode='categorical',\n","                                                        batch_size=8,\n","                                                        shuffle=True,\n","                                                        seed=seed)\n","                                              \n","                                              \n","  valid_gen = ImageDataGenerator(\n","      ).flow_from_directory(directory=validation_dir,\n","                                                target_size=(96,96),\n","                                                color_mode='rgb',\n","                                                classes=None, # can be set to labels\n","                                                class_mode='categorical',\n","                                                batch_size=8,\n","                                                shuffle=False,\n","                                                seed=seed)\n","  test_gen = ImageDataGenerator(\n","  ).flow_from_directory(directory=test_dir,\n","                                                target_size=(96,96),\n","                                                color_mode='rgb',\n","                                                classes=None, # can be set to labels\n","                                                class_mode='categorical',\n","                                                batch_size=8,\n","                                                shuffle=False,\n","                                                seed=seed)\n","##########################################################\n","  supernet = tfk.applications.EfficientNetV2L(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_shape=(96,96,3),\n","    pooling='avg',\n","    include_preprocessing=True\n",")\n","  \n","  elastic_lambda= hp.Float(\"reg\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n","\n","  # Use the supernet as feature extractor\n","  supernet.trainable = False\n","\n","  inputs = tfk.Input(shape=(96,96,3))\n","  x = tfkl.Resizing(96,96, interpolation=\"bicubic\")(inputs)\n","  x = supernet(x) \n","  x = tfkl.Dropout(0.5, seed=seed)(x)    #0.3\n","  x = tfkl.Dense( \n","      units=hp.Int(\"units\", min_value=32, max_value=512, step=32), \n","      kernel_initializer = tfk.initializers.HeUniform(seed),\n","      kernel_regularizer=tf.keras.regularizers.L1L2(elastic_lambda,elastic_lambda))(x)\n","  x=tfkl.LeakyReLU()(x)\n","  x = tfkl.Dropout(0.5, seed=seed)(x)    #0.3\n","  outputs = tfkl.Dense(\n","      8, \n","      activation='softmax',\n","      kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n","\n","\n","  # Connect input and output through the Model class\n","  tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","  learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n","  tl_model.compile(\n","  optimizer=tfk.optimizers.Adam(learning_rate=learning_rate),\n","  loss=\"categorical_crossentropy\",\n","  metrics=[\"accuracy\"],\n","  )\n","  return tl_model"],"metadata":{"id":"m59Aia7Vq-Mf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Hyperparameter search\n","1. build the model"],"metadata":{"id":"UluWVmeGq-Mg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-eu6oo2q-Mg"},"outputs":[],"source":["build_model(keras_tuner.HyperParameters())"]},{"cell_type":"markdown","source":["2. initialize the tuner. We decided to use a random search."],"metadata":{"id":"O-WD5ibSq-Mg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sfm3p9Zpq-Mh"},"outputs":[],"source":["tuner = keras_tuner.RandomSearch(\n","    hypermodel=build_model,\n","    objective=\"val_accuracy\",\n","    max_trials=10,\n","    executions_per_trial=2,\n","    overwrite=False,\n","    directory=\"my_dir\",\n","    project_name=\"tuningL\",\n",")"]},{"cell_type":"markdown","source":["3. Run the search and get the results"],"metadata":{"id":"vATfy3ohq-Mh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CSCt10XFq-Mi"},"outputs":[],"source":["tuner.search(aug_train_gen,epochs=2, validation_data=valid_gen)\n","tuner.results_summary()"]},{"cell_type":"markdown","source":["4. Get the best model found by the hyperparameter tuning"],"metadata":{"id":"FC0NHV81q-Mi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2eF95OWq-Mj"},"outputs":[],"source":["# Get the top 2 models.\n","models = tuner.get_best_models(num_models=2)\n","best_model = models[0]\n","# Build the model.\n","# Needed for `Sequential` without specified `input_shape`.\n","best_model.build(input_shape=(96,96,3))\n","best_model.summary()\n"]},{"cell_type":"markdown","source":["####Transfer learning\n","We run a transfer learning step directly on the best model found by the hyperparameter tuning"],"metadata":{"id":"scrVeYRQq-Mj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_nkqTAeuq-Mk"},"outputs":[],"source":["# Train the model\n","best_history = best_model.fit(\n","    aug_train_gen,\n","    epochs = 200,  \n","    validation_data = valid_gen,\n","    class_weight=class_weights,\n","    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",").history"]},{"cell_type":"code","metadata":{"id":"dtE0W2vPq-Mk"},"source":["# Plot the training\n","plt.figure(figsize=(15,5))\n","plt.plot(best_history['loss'], label='Training', alpha=.3, color='blue')\n","plt.plot(best_history['val_loss'], label='Validation', alpha=.8, color='red')\n","plt.legend(loc='upper left')\n","plt.title('Categorical Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(best_history['accuracy'], label='Training', alpha=.8, color='blue')\n","plt.plot(best_history['val_accuracy'], label='Validation', alpha=.8, color='red')\n","plt.legend(loc='upper left')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B6VP7Ozbq-Mk"},"outputs":[],"source":["# Predict the test set with the CNN\n","predictions = best_model.predict(test_gen)\n","predictions.shape\n","\n","pred=np.argmax(predictions,axis=1)\n","# Compute the confusion matrix\n","cm = confusion_matrix(test_gen.classes, pred)\n","\n","pred=np.argmax(predictions,axis=-1)\n","\n","# Compute the classification metrics\n","accuracy = accuracy_score(test_gen.classes, pred)\n","precision = precision_score(test_gen.classes, pred, average='macro')\n","recall = recall_score(test_gen.classes, pred, average='macro')\n","f1 = f1_score(test_gen.classes, pred, average='macro')\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(10,8))\n","sns.heatmap(cm.T, xticklabels=labels, yticklabels=labels)\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7E0ySqh6q-Ml"},"outputs":[],"source":["best_model.save(\"ANN&DL_Model/TL_EFFNETL\")"]},{"cell_type":"markdown","metadata":{"id":"aRaKyBEMq-Ml"},"source":["#### Fine tuning\n","Reload the model and run a step of fine tuning over it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1cNBTd7q-Mm"},"outputs":[],"source":["# Re-load the model after transfer learning\n","path='ANN&DL_Model'\n","ft_model = tfk.models.load_model(os.path.join(path, 'TL_EFFNETL'))\n","ft_model.summary()"]},{"cell_type":"markdown","source":[" Set all effnet layers to True. We kept the batch normalization layers freezed. We followed the keras documentation for Fine Tuning on the Efficient net. \"The BatchNormalization layers need to be kept frozen. If they are also turned to trainable, the first epoch after unfreezing will significantly reduce accuracy.\""],"metadata":{"id":"PY6SZT9sq-Mm"}},{"cell_type":"code","source":["\n","for i, layer in enumerate(ft_model.layers):  \n","   if not isinstance(layer, tfkl.BatchNormalization):\n","        layer.trainable=True\n","        \n","for i, layer in enumerate(ft_model.layers):  \n","    print(i, layer.name, layer.trainable)\n","ft_model.summary()"],"metadata":{"id":"k9AiK9URq-Mn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Freeze first 250 layers. The number of layers to freeze as been found experimentally. We tried with 150, 350 layers. The chosen combination was the one giving the best performance."],"metadata":{"id":"TMZ5-Saxq-Mn"}},{"cell_type":"code","source":["\n","for i, layer in enumerate(ft_model.get_layer('efficientnetv2-l').layers[:650]):  \n","        layer.trainable=False\n","        \n","for i, layer in enumerate(ft_model.get_layer('efficientnetv2-l').layers):  \n","     if isinstance(layer, tfkl.BatchNormalization):\n","        layer.trainable=False\n","        \n","for i, layer in enumerate(ft_model.get_layer('efficientnetv2-l').layers):  \n","   print(i, layer.name, layer.trainable)\n","ft_model.summary()"],"metadata":{"id":"_RIZ1W_Uq-Mo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For the finetuning we used a learning rate 10 times smaller than the one used for the transfer learning phase."],"metadata":{"id":"mTYV4Rn7q-Mo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LglMZhgjq-Mp"},"outputs":[],"source":["# Compile the model\n","ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5PEgOmyXq-Mp"},"outputs":[],"source":["# Fine-tune the model\n","ft_history = ft_model.fit(\n","    x = aug_train_gen,\n","    batch_size = 256,\n","    epochs = 200,\n","    validation_data = valid_gen,\n","    class_weight=w,\n","    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",").history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8Cy7HZYq-Mq"},"outputs":[],"source":["# Plot the training\n","plt.figure(figsize=(15,5))\n","plt.plot(tl_history['loss'], alpha=.3, color='#4D61E2', linestyle='--')\n","plt.plot(tl_history['val_loss'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n","plt.plot(ft_history['loss'], alpha=.3, color='#2ABC3D', linestyle='--')\n","plt.plot(ft_history['val_loss'], label='Fine Tuning', alpha=.8, color='#2ABC3D')\n","plt.legend(loc='upper left')\n","plt.title('Categorical Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(tl_history['accuracy'], alpha=.3, color='#4D61E2', linestyle='--')\n","plt.plot(tl_history['val_accuracy'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n","plt.plot(ft_history['accuracy'], alpha=.3, color='#2ABC3D', linestyle='--')\n","plt.plot(ft_history['val_accuracy'], label='Fine Tuning', alpha=.8, color='#2ABC3D')\n","plt.legend(loc='upper left')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEw4H0xbq-Mq"},"outputs":[],"source":["# Predict the test set with the CNN\n","predictions = ft_model.predict(test_gen)\n","predictions.shape\n","\n","pred=np.argmax(predictions,axis=1)\n","# Compute the confusion matrix\n","cm = confusion_matrix(test_gen.classes, pred)\n","\n","pred=np.argmax(predictions,axis=-1)\n","\n","# Compute the classification metrics\n","accuracy = accuracy_score(test_gen.classes, pred)\n","precision = precision_score(test_gen.classes, pred, average='macro')\n","recall = recall_score(test_gen.classes, pred, average='macro')\n","f1 = f1_score(test_gen.classes, pred, average='macro')\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(10,8))\n","sns.heatmap(cm.T, xticklabels=labels, yticklabels=labels)\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n6QxpzBEq-Mr"},"outputs":[],"source":["ft_model.save('ANN&DL_Model/FT_EFFNETL')"]},{"cell_type":"markdown","source":["##Ensemble\n","Now having the two models we build the ensemble of the two.\n","The ensemble method puts together several models and the output of the ensemble model will be the average of the outputs of the different input models."],"metadata":{"id":"c99fbP_ctBdp"}},{"cell_type":"code","source":["def ensemble(models, model_input):\n","    \n","    model_outputs=[]\n","    for i in range(len(models)):\n","      model=models[i]\n","      model._name=\"model\" + str(i)\n","      model_outputs.append(model(model_input))\n","    \n","    ensemble_output = tfkl.Average()(model_outputs)\n","    ensemble_model = tf.keras.Model(inputs=model_input, outputs=ensemble_output)\n","    \n","    return ensemble_model"],"metadata":{"id":"Ag5ErczFtHhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["effnetS=tfk.models.load_model(os.path.join(path, 'FT_EFFNETS'))\n","effnetL=tfk.models.load_model(os.path.join(path, 'FT_EFFNETL'))\n","inputs = tfk.Input(shape=(96,96,3))\n","final_model=ensemble([effnetS,effnetL],inputs)"],"metadata":{"id":"BNnrRDe9t2Ty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict the test set with the CNN\n","predictions = final_model.predict(test_gen)\n","predictions.shape\n","\n","pred=np.argmax(predictions,axis=1)\n","# Compute the confusion matrix\n","cm = confusion_matrix(test_gen.classes, pred)\n","\n","pred=np.argmax(predictions,axis=-1)\n","\n","# Compute the classification metrics\n","accuracy = accuracy_score(test_gen.classes, pred)\n","precision = precision_score(test_gen.classes, pred, average='macro')\n","recall = recall_score(test_gen.classes, pred, average='macro')\n","f1 = f1_score(test_gen.classes, pred, average='macro')\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(10,8))\n","sns.heatmap(cm.T, xticklabels=labels, yticklabels=labels)\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()"],"metadata":{"id":"EUXF1BGWAEv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_model.save('ANN&DL_Model/Final_model')"],"metadata":{"id":"QZTI3hSIuxJq"},"execution_count":null,"outputs":[]}]}